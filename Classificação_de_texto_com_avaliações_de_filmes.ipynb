{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TDRL2QJVHaBw",
        "1MTO1veEH5vL",
        "9W3i309KIg0W",
        "y_amUaRrNVKz",
        "4HlZvw8NPgPB"
      ],
      "authorship_tag": "ABX9TyMexGPoIsxN98d6xJdbT5sC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leonamcassemir0/Machine-Learning/blob/main/Classifica%C3%A7%C3%A3o_de_texto_com_avalia%C3%A7%C3%B5es_de_filmes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importando bibliotecas"
      ],
      "metadata": {
        "id": "TDRL2QJVHaBw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UGtEX4FqCAYN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acb38c14-7649-4d58-ab64-11803b8d8646"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baixando o IMDB"
      ],
      "metadata": {
        "id": "1MTO1veEH5vL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imdb = keras.datasets.imdb\n",
        "\n",
        "(train_data, train_label), (test_data, test_label) = imdb.load_data(num_words=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00RZJHptH9MR",
        "outputId": "8710f325-be22-45fa-d290-69cc3442e726"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O argumento ***num_words=10000*** mantém as 10000 palavras mais frequentes no conjunto de treinamento. As palavras mais raras são descartadas para preservar o tamanho dos dados de forma maleável."
      ],
      "metadata": {
        "id": "AQEFJYsYIbQl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explore o dados"
      ],
      "metadata": {
        "id": "9W3i309KIg0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training entries: {}, labels: {}\".format(len(train_data), len(train_label)))\n",
        "print(train_data[0])\n",
        "len(train_data[0]), len(train_data[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eVGl-4MIjqf",
        "outputId": "7bd9d577-6f79-4a01-cd02-f22f2a6902ce"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training entries: 25000, labels: 25000\n",
            "[1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(218, 189)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convertendo os índices para palavras"
      ],
      "metadata": {
        "id": "y_amUaRrNVKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Um dicionário mapeando palavras em índices inteiros\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# Os primeiros índices são reservados\n",
        "word_index = {k:(v+3) for k,v in word_index.items()}\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  # unknown\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsfapmXGNcg6",
        "outputId": "e57b7e65-7636-4908-cb19-8388e2b3cd04"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***.get_word_index()*** é um método para obter um dicionário que mapeia palavras para índices inteiros com base em sua frequência no conjunto de dados do IMDb.\n",
        "\n",
        "***.items()*** retorna uma visão de objetos do dicionário, que contém pares de chave-valor como tuplas.  \n",
        "*   Isso é útil quando você precisa iterar sobre um dicionário acessando tanto as chaves quanto os valores ao mesmo tempo.\n",
        "\n",
        "***.get(key, default_value)*** permite especificar um valor padrão que será retornado caso a chave não exista no dicionário.\n",
        "\n",
        "***.join(iterable)*** é usado para concatenar uma lista de strings em uma única string, usando um separador especificado."
      ],
      "metadata": {
        "id": "LizGgto1NeLa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Podemos verificar a análise do primeiro filme"
      ],
      "metadata": {
        "id": "4HlZvw8NPgPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decode_review(train_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "H8QQf7xuPuWR",
        "outputId": "891a72a2-dbf0-4a6d-c151-49da64adb5ea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<START> this film was just brilliant casting <UNK> <UNK> story direction <UNK> really <UNK> the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same <UNK> <UNK> as myself so i loved the fact there was a real <UNK> with this film the <UNK> <UNK> throughout the film were great it was just brilliant so much that i <UNK> the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the <UNK> <UNK> was amazing really <UNK> at the end it was so sad and you know what they say if you <UNK> at a film it must have been good and this definitely was also <UNK> to the two little <UNK> that played the <UNK> of <UNK> and paul they were just brilliant children are often left out of the <UNK> <UNK> i think because the stars that play them all <UNK> up are such a big <UNK> for the whole film but these children are amazing and should be <UNK> for what they have done don't you think the whole story was so <UNK> because it was true and was <UNK> life after all that was <UNK> with us all\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare os dados"
      ],
      "metadata": {
        "id": "opK6M3qqQKd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
        "                                                        value=word_index[\"<PAD>\"],\n",
        "                                                        padding='pre',\n",
        "                                                        maxlen=256)\n",
        "\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
        "                                                       value=word_index[\"<PAD>\"],\n",
        "                                                       padding='pre',\n",
        "                                                       maxlen=256)\n",
        "\n",
        "print(train_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzoM0VyfK09Q",
        "outputId": "3fd780e3-671e-4465-d9ab-a6d6bfc890db"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1  14  22  16  43 530 973   2   2  65 458   2  66   2   4 173  36 256\n",
            "   5  25 100  43 838 112  50 670   2   9  35 480 284   5 150   4 172 112\n",
            " 167   2 336 385  39   4 172   2   2  17 546  38  13 447   4 192  50  16\n",
            "   6 147   2  19  14  22   4   2   2 469   4  22  71  87  12  16  43 530\n",
            "  38  76  15  13   2   4  22  17 515  17  12  16 626  18   2   5  62 386\n",
            "  12   8 316   8 106   5   4   2   2  16 480  66   2  33   4 130  12  16\n",
            "  38 619   5  25 124  51  36 135  48  25   2  33   6  22  12 215  28  77\n",
            "  52   5  14 407  16  82   2   8   4 107 117   2  15 256   4   2   7   2\n",
            "   5 723  36  71  43 530 476  26 400 317  46   7   4   2   2  13 104  88\n",
            "   4 381  15 297  98  32   2  56  26 141   6 194   2  18   4 226  22  21\n",
            " 134 476  26 480   5 144  30   2  18  51  36  28 224  92  25 104   4 226\n",
            "  65  16  38   2  88  12  16 283   5  16   2 113 103  32  15  16   2  19\n",
            " 178  32   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "***pad_sequences( )*** esta função ajusta (preenche ou corta) as sequências de inteiros para que todas tenham o mesmo comprimento.\n",
        "\n",
        "* ***value=word_index[ ]***: é um token especial usado para preenchimento, e o valor correspondente a este token no dicionário word_index é utilizado para preencher as sequências.\n",
        "* **padding='post'**:Indica que o preenchimento deve ser adicionado ao final das sequências.\n",
        "* **maxlen=256**: Define o comprimento máximo das sequências após o preenchimento ou corte.\n",
        "\n",
        "### Resultado:\n",
        "Após a execução deste código:\n",
        "- Todas as sequências em `train_data` e `test_data` terão um comprimento de 256.\n",
        "- As sequências que originalmente tinham menos de 256 elementos serão preenchidas com o valor correspondente a `\"<PAD>\"` no final.\n",
        "- As sequências que eram mais longas serão cortadas, mantendo apenas os primeiros 256 elementos.\n"
      ],
      "metadata": {
        "id": "G1mvTmZHMcbD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construindo o modelo"
      ],
      "metadata": {
        "id": "p0a63cTSSMeZ"
      }
    }
  ]
}